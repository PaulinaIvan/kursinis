{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8rBolZtzE12"
      },
      "source": [
        "## Importuotos bibliotekos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UExLZvmQzE12"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict, deque\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, List, Dict, Any\n",
        "from datetime import datetime\n",
        "import copy\n",
        "import itertools\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Up-fyonzE13"
      },
      "source": [
        "## Parametrai\n",
        "\n",
        "### α (Alpha) - Mokymosi greitis\n",
        "\n",
        "**Formulė:**\n",
        "$$Q_{naujas} = Q_{senas} + \\alpha \\cdot (target - Q_{senas})$$\n",
        "\n",
        "**Ką reiškia α:**\n",
        "- **α = 0**: Nieko nesimoko (ignoruoja naują informaciją)\n",
        "- **α = 0.5**: Greitas mokymasis (50% naujo + 50% seno)\n",
        "- **α = 1.0**: Mokosi tik iš naujos informacijos (100% naujo)\n",
        "\n",
        "---\n",
        "\n",
        "### γ (Gamma) - Nuolaidos faktorius\n",
        "\n",
        "**Formulė:**\n",
        "$$target = r + \\gamma \\cdot Q(s', a')$$\n",
        "\n",
        "**Ką reiškia γ:**\n",
        "- **γ = 0**: Žiūri tik į dabartinį atlygį (trumparegis)\n",
        "- **γ = 0.9**: Ateitis beveik tokia pat svarbi kaip dabartis\n",
        "- **γ = 1.0**: Ateitis lygiai tokia pat svarbi\n",
        "\n",
        "---\n",
        "\n",
        "### ε (Epsilon) - Tyrinėjimų tikimybė\n",
        "\n",
        "**Formulė (Epsilon-Greedy):**\n",
        "$$a = \\begin{cases} random(A) & \\text{su tikimybe } \\epsilon \\\\ \\arg\\max_a Q(s,a) & \\text{su tikimybe } 1-\\epsilon \\end{cases}$$\n",
        "\n",
        "**Ką reiškia ε:**\n",
        "- **ε = 0.05**: 5% atsitiktinis, 95% geriausias\n",
        "- **ε = 0.15**: 15% atsitiktinis, 85% geriausias\n",
        "- **ε = 0.30**: 30% atsitiktinis, 70% geriausias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeE4WHDSzE13"
      },
      "source": [
        "## Parametrų matrica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJLxkA1PzE14"
      },
      "outputs": [],
      "source": [
        "PARAM_GRID = {\n",
        "    'alpha': [0.1, 0.3, 0.5],\n",
        "    'gamma': [0.5, 0.9, 0.99],\n",
        "    'epsilon': [0.05, 0.15, 0.30],\n",
        "    'exploration_method': ['epsilon_greedy', 'thompson_sampling'],\n",
        "    'strategy': ['A', 'B', 'C'],\n",
        "    'similarity_method': ['cosine', 'euclidean'],\n",
        "}\n",
        "\n",
        "MODEL_NAMES = ['Q-Learning', 'SARSA', 'Expected-SARSA']\n",
        "\n",
        "n_alpha = len(PARAM_GRID['alpha'])\n",
        "n_gamma = len(PARAM_GRID['gamma'])\n",
        "n_epsilon = len(PARAM_GRID['epsilon'])\n",
        "n_exploration = len(PARAM_GRID['exploration_method'])\n",
        "n_strategy = len(PARAM_GRID['strategy'])\n",
        "n_similarity = len(PARAM_GRID['similarity_method'])\n",
        "n_models = len(MODEL_NAMES)\n",
        "\n",
        "total_combinations = n_models * n_alpha * n_gamma * n_epsilon * n_exploration * n_strategy * n_similarity\n",
        "\n",
        "print(f\"Alpha: {PARAM_GRID['alpha']}\")\n",
        "print(f\"Gamma: {PARAM_GRID['gamma']}\")\n",
        "print(f\"Epsilon: {PARAM_GRID['epsilon']}\")\n",
        "print(f\"Tyrinėjimo metodai: {PARAM_GRID['exploration_method']}\")\n",
        "print(f\"Strategijos: {PARAM_GRID['strategy']}\")\n",
        "print(f\"Panašumo metodai: {PARAM_GRID['similarity_method']}\")\n",
        "print(f\"Modeliai: {MODEL_NAMES}\")\n",
        "print(f\"\\nKombinacijų skaičius: {total_combinations}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQWuK_gAzE15"
      },
      "source": [
        "## Vaisių savybės\n",
        "\n",
        "| Savybė | Aprašymas | Skalė |\n",
        "|--------|-----------|-------|\n",
        "| kietumas | Kiek kietas vaisius | 0 (minkštas) → 1 (kietas) |\n",
        "| saldumas | Kiek saldus | 0 (nesaldus) → 1 (labai saldus) |\n",
        "| rūgštingumas | Kiek rūgštus | 0 (nerūgštus) → 1 (labai rūgštus) |\n",
        "| forma | Formos neįprastumas | 0 (apvalus) → 1 (pailgas) |\n",
        "| tekstūra | Paviršiaus tekstūra | 0 (lygus) → 1 (šiurkštus) |\n",
        "| spalva | Spalvos tonas | 0 (raudona) → 1 (mėlyna) |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zVSNK9-zE15"
      },
      "outputs": [],
      "source": [
        "FOOD_DATABASE = {\n",
        "    'Obuolys': {'kietumas': 0.8, 'saldumas': 0.7, 'rugstingumas': 0.4, 'forma': 0.0, 'tekstura': 0.2, 'spalva': 0.0},\n",
        "    'Žaliasis obuolys': {'kietumas': 0.8, 'saldumas': 0.5, 'rugstingumas': 0.7, 'forma': 0.0, 'tekstura': 0.2, 'spalva': 0.66},\n",
        "    'Kriaušė': {'kietumas': 0.6, 'saldumas': 0.8, 'rugstingumas': 0.2, 'forma': 0.3, 'tekstura': 0.3, 'spalva': 0.5},\n",
        "    'Bananas': {'kietumas': 0.3, 'saldumas': 0.9, 'rugstingumas': 0.1, 'forma': 1.0, 'tekstura': 0.0, 'spalva': 0.33},\n",
        "    'Persikai': {'kietumas': 0.4, 'saldumas': 0.8, 'rugstingumas': 0.2, 'forma': 0.0, 'tekstura': 0.8, 'spalva': 0.15},\n",
        "    'Mangas': {'kietumas': 0.5, 'saldumas': 0.9, 'rugstingumas': 0.3, 'forma': 0.2, 'tekstura': 0.1, 'spalva': 0.25},\n",
        "    'Apelsinas': {'kietumas': 0.6, 'saldumas': 0.7, 'rugstingumas': 0.5, 'forma': 0.0, 'tekstura': 0.4, 'spalva': 0.2},\n",
        "    'Mandarinas': {'kietumas': 0.5, 'saldumas': 0.8, 'rugstingumas': 0.4, 'forma': 0.0, 'tekstura': 0.3, 'spalva': 0.2},\n",
        "    'Arbūzas': {'kietumas': 0.3, 'saldumas': 0.8, 'rugstingumas': 0.1, 'forma': 0.0, 'tekstura': 0.0, 'spalva': 0.0},\n",
        "    'Melionas': {'kietumas': 0.4, 'saldumas': 0.7, 'rugstingumas': 0.1, 'forma': 0.0, 'tekstura': 0.1, 'spalva': 0.4},\n",
        "    'Ananasas': {'kietumas': 0.6, 'saldumas': 0.8, 'rugstingumas': 0.6, 'forma': 0.5, 'tekstura': 0.9, 'spalva': 0.33},\n",
        "    'Kiviai': {'kietumas': 0.5, 'saldumas': 0.6, 'rugstingumas': 0.5, 'forma': 0.0, 'tekstura': 0.6, 'spalva': 0.66},\n",
        "    'Vyšnios': {'kietumas': 0.7, 'saldumas': 0.7, 'rugstingumas': 0.3, 'forma': 0.0, 'tekstura': 0.1, 'spalva': 0.0},\n",
        "    'Braškės': {'kietumas': 0.4, 'saldumas': 0.8, 'rugstingumas': 0.2, 'forma': 0.4, 'tekstura': 0.5, 'spalva': 0.0},\n",
        "    'Mėlynės': {'kietumas': 0.5, 'saldumas': 0.6, 'rugstingumas': 0.4, 'forma': 0.0, 'tekstura': 0.1, 'spalva': 1.0},\n",
        "    'Avietės': {'kietumas': 0.3, 'saldumas': 0.7, 'rugstingumas': 0.3, 'forma': 0.1, 'tekstura': 0.7, 'spalva': 0.05},\n",
        "    'Vynuogės': {'kietumas': 0.6, 'saldumas': 0.8, 'rugstingumas': 0.2, 'forma': 0.0, 'tekstura': 0.0, 'spalva': 0.8}\n",
        "}\n",
        "\n",
        "PROPERTY_COLS = ['kietumas', 'saldumas', 'rugstingumas', 'forma', 'tekstura', 'spalva']\n",
        "\n",
        "food_data = [\n",
        "    {'pavadinimas': name, **props}\n",
        "    for name, props in FOOD_DATABASE.items()\n",
        "]\n",
        "\n",
        "FOOD_DF = pd.DataFrame(food_data)\n",
        "FOOD_LIST = FOOD_DF['pavadinimas'].tolist()\n",
        "\n",
        "print(f\"{len(FOOD_DF)} produktų, {len(PROPERTY_COLS)} savybės\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCmc0UOXzE16"
      },
      "source": [
        "## Panašumo metodai\n",
        "\n",
        "### 1. Kosinuso panašumas (Cosine Similarity)\n",
        "\n",
        "**Formulė:**\n",
        "$$\\text{cosine}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\times \\|B\\|} = \\frac{\\sum_{i=1}^{n} A_i \\times B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\times \\sqrt{\\sum_{i=1}^{n} B_i^2}}$$\n",
        "\n",
        "**Kur:**\n",
        "- $A$ = pirmo vaisiaus savybių vektorius, pvz. Bananas = [0.3, 0.9, 0.1, 1.0, 0.0, 0.33]\n",
        "- $B$ = antro vaisiaus savybių vektorius, pvz. Mangas = [0.5, 0.9, 0.3, 0.2, 0.1, 0.25]\n",
        "- $A \\cdot B$ = skaliarinė sandauga (dot product)\n",
        "- $\\|A\\|$ = vektoriaus A ilgis (norma)\n",
        "- $n$ = savybių skaičius (6)\n",
        "\n",
        "**Rezultatas:**\n",
        "- 0 = visiškai skirtingi (90° kampas)\n",
        "- 1 = identiški (0° kampas)\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Euklido panašumas (Euclidean Similarity)\n",
        "\n",
        "**Atstumas:**\n",
        "$$\\text{distance}(A, B) = \\sqrt{\\sum_{i=1}^{n} (A_i - B_i)^2}$$\n",
        "\n",
        "**Konversija į panašumą:**\n",
        "$$\\text{similarity} = \\frac{1}{1 + \\text{distance}}$$\n",
        "\n",
        "**Kur:**\n",
        "- $(A_i - B_i)^2$ = skirtumo kvadratas kiekvienai savybei\n",
        "- Konversija reikalinga nes atstumas = kuo didesnis, tuo mažiau panašūs\n",
        "\n",
        "**Rezultatas:**\n",
        "- ~0 = labai skirtingi (didelis atstumas)\n",
        "- 1 = identiški (atstumas = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXSe3Z_ZzE17"
      },
      "outputs": [],
      "source": [
        "def compute_similarity_matrix(method='cosine'):\n",
        "\n",
        "    vectors = FOOD_DF[PROPERTY_COLS].values\n",
        "    n = len(vectors)\n",
        "\n",
        "    if method == 'cosine':\n",
        "        norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
        "        norms[norms == 0] = 1\n",
        "        normalized = vectors / norms\n",
        "        sim = normalized @ normalized.T\n",
        "    else:  # euclidean\n",
        "        sim = np.zeros((n, n))\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if i != j:\n",
        "                    dist = np.sqrt(np.sum((vectors[i] - vectors[j])**2))\n",
        "                    sim[i][j] = 1 / (1 + dist)\n",
        "\n",
        "    np.fill_diagonal(sim, 0)\n",
        "    return sim\n",
        "\n",
        "SIMILARITY_MATRICES = {\n",
        "    'cosine': compute_similarity_matrix('cosine'),\n",
        "    'euclidean': compute_similarity_matrix('euclidean')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztOz74rkzE17"
      },
      "source": [
        "---\n",
        "## Būsena (STATE)\n",
        "\n",
        "\n",
        "**State:**\n",
        "$$S = (rejections, last\\_action)$$\n",
        "\n",
        "**Kur:**\n",
        "- $rejections$ = kiek kartų vaikas atmetė šioje sesijoje (0, 1, 2, 3)\n",
        "- $last\\_action$ = paskutinis veiksmas ('start', 'success', 'rejection')\n",
        "\n",
        "**Galimos būsenos:**\n",
        "```\n",
        "S(0, start)     - Sesijos pradžia\n",
        "S(0, success)   - Atiktis be atmetimų\n",
        "S(1, rejection) - Po pirmo atmetimo\n",
        "S(2, rejection) - Po antro atmetimo  \n",
        "S(3, rejection) - Po trečio atmetimo\n",
        "```\n",
        "\n",
        "**Viso galimų būsenų:** 4 × 3 = 12\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxjp0Fd8zE17"
      },
      "source": [
        "## Būsena"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpHWcDh5zE17"
      },
      "outputs": [],
      "source": [
        "@dataclass(frozen=True)\n",
        "class State:\n",
        "    rejections: int\n",
        "    last_action: str\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"S(rej={self.rejections},{self.last_action[:3]})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JtNtGD2zE18"
      },
      "source": [
        "## Virtualaus vaiko norų sąrašas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO8XN4qszE18"
      },
      "outputs": [],
      "source": [
        "CHILD_WANTS = [\n",
        "    \"Bananas\", \"Bananas\", \"Mangas\", \"Bananas\", \"Mangas\",\n",
        "    \"Bananas\", \"Bananas\", \"Mangas\", \"Bananas\", \"Mandarinas\",\n",
        "    \"Bananas\", \"Bananas\", \"Mangas\", \"Bananas\", \"Mangas\",\n",
        "    \"Bananas\", \"Bananas\", \"Obuolys\", \"Obuolys\", \"Kriaušė\",\n",
        "    \"Kriaušė\", \"Bananas\", \"Obuolys\", \"Kriaušė\", \"Bananas\",\n",
        "    \"Obuolys\", \"Kriaušė\", \"Mandarinas\", \"Obuolys\", \"Kriaušė\",\n",
        "    \"Bananas\", \"Obuolys\", \"Obuolys\", \"Kriaušė\", \"Bananas\",\n",
        "    \"Mangas\", \"Bananas\", \"Obuolys\", \"Kriaušė\", \"Mandarinas\",\n",
        "    \"Bananas\", \"Bananas\", \"Mėlynės\", \"Mėlynės\", \"Vynuogės\",\n",
        "    \"Vynuogės\", \"Bananas\", \"Mėlynės\", \"Vynuogės\", \"Mandarinas\",\n",
        "    \"Mėlynės\", \"Vynuogės\", \"Bananas\", \"Obuolys\", \"Kriaušė\",\n",
        "    \"Mėlynės\", \"Vynuogės\", \"Bananas\", \"Mandarinas\", \"Mėlynės\",\n",
        "    \"Vynuogės\", \"Bananas\", \"Mangas\", \"Bananas\", \"Bananas\",\n",
        "    \"Obuolys\", \"Bananas\", \"Mandarinas\", \"Bananas\", \"Kriaušė\",\n",
        "    \"Bananas\", \"Mėlynės\", \"Bananas\", \"Vynuogės\", \"Bananas\",\n",
        "    \"Bananas\", \"Mandarinas\", \"Bananas\", \"Mangas\", \"Bananas\",\n",
        "    \"Obuolys\", \"Bananas\", \"Obuolys\", \"Bananas\", \"Bananas\",\n",
        "    \"Mėlynės\", \"Mandarinas\", \"Obuolys\", \"Mandarinas\", \"Bananas\",\n",
        "    \"Mandarinas\", \"Obuolys\", \"Mangas\", \"Mėlynės\", \"Bananas\",\n",
        "    \"Vynuogės\", \"Mangas\", \"Mėlynės\", \"Obuolys\", \"Bananas\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifoRlMH3zE18"
      },
      "source": [
        "## Rezultatų logger'is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtRzlv9wzE18"
      },
      "outputs": [],
      "source": [
        "class ExtendedResultsLogger:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.records = []\n",
        "        self.cumulative_success = 0\n",
        "        self.cumulative_rejection = 0\n",
        "        self.recent_results = deque(maxlen=20)\n",
        "        self.current_success_streak = 0\n",
        "        self.current_fail_streak = 0\n",
        "        self.max_success_streak = 0\n",
        "        self.max_fail_streak = 0\n",
        "\n",
        "    def reset_cumulative(self):\n",
        "        self.cumulative_success = 0\n",
        "        self.cumulative_rejection = 0\n",
        "        self.recent_results.clear()\n",
        "        self.current_success_streak = 0\n",
        "        self.current_fail_streak = 0\n",
        "        self.max_success_streak = 0\n",
        "        self.max_fail_streak = 0\n",
        "\n",
        "    def log(self,\n",
        "            # Pagrindiniai\n",
        "            session: int,\n",
        "            wanted: str,\n",
        "            card1: str,\n",
        "            card2: str,\n",
        "            result: str,  # 'SUCCESS' arba 'REJECTION'\n",
        "            chosen: str,  # Pasirinkta kortelė arba ''\n",
        "            set_number: int,\n",
        "            state: State,\n",
        "            selection_reason: str,\n",
        "\n",
        "            # Konfigūracija\n",
        "            model_name: str,\n",
        "            exploration: str,\n",
        "            strategy: str,\n",
        "            alpha: float,\n",
        "            gamma: float,\n",
        "            epsilon: float,\n",
        "            similarity_method: str,\n",
        "\n",
        "            # Q reikšmės\n",
        "            q1_before: float,\n",
        "            q2_before: float,\n",
        "            q1_after: float,\n",
        "            q2_after: float,\n",
        "\n",
        "            # Tyrinėjimas\n",
        "            was_exploration: bool,\n",
        "            best_q_card: str,\n",
        "            best_q_value: float,\n",
        "\n",
        "            # Thompson Sampling (jei taikoma)\n",
        "            ts_sample_card1: Optional[float],\n",
        "            ts_sample_card2: Optional[float],\n",
        "\n",
        "            # Panašumas\n",
        "            similarity_card1_to_rejected: float,\n",
        "            similarity_card2_to_rejected: float,\n",
        "\n",
        "            # Sesija\n",
        "            session_success: bool,\n",
        "            ):\n",
        "\n",
        "        if result == 'SUCCESS':\n",
        "            self.cumulative_success += 1\n",
        "            self.current_success_streak += 1\n",
        "            self.current_fail_streak = 0\n",
        "            self.max_success_streak = max(self.max_success_streak, self.current_success_streak)\n",
        "        else:\n",
        "            self.cumulative_rejection += 1\n",
        "            self.current_fail_streak += 1\n",
        "            self.current_success_streak = 0\n",
        "            self.max_fail_streak = max(self.max_fail_streak, self.current_fail_streak)\n",
        "\n",
        "        self.recent_results.append(1 if result == 'SUCCESS' else 0)\n",
        "\n",
        "        last_10_rate = sum(list(self.recent_results)[-10:]) / min(10, len(self.recent_results)) if self.recent_results else 0\n",
        "        last_20_rate = sum(self.recent_results) / len(self.recent_results) if self.recent_results else 0\n",
        "\n",
        "        q1_change = q1_after - q1_before\n",
        "        q2_change = q2_after - q2_before\n",
        "\n",
        "        record = {\n",
        "            # Pagrindiniai\n",
        "            'session': session,\n",
        "            'set_number': set_number,\n",
        "            'wanted': wanted,\n",
        "            'card1': card1,\n",
        "            'card2': card2,\n",
        "            'result': result,\n",
        "            'chosen': chosen,\n",
        "            'state': str(state),\n",
        "            'selection_reason': selection_reason,\n",
        "\n",
        "            # Konfigūracija\n",
        "            'model': model_name,\n",
        "            'exploration': exploration,\n",
        "            'strategy': strategy,\n",
        "            'alpha': alpha,\n",
        "            'gamma': gamma,\n",
        "            'epsilon': epsilon,\n",
        "            'similarity_method': similarity_method,\n",
        "\n",
        "            # Q reikšmės\n",
        "            'q1_before': round(q1_before, 4),\n",
        "            'q2_before': round(q2_before, 4),\n",
        "            'q1_after': round(q1_after, 4),\n",
        "            'q2_after': round(q2_after, 4),\n",
        "            'q1_change': round(q1_change, 4),\n",
        "            'q2_change': round(q2_change, 4),\n",
        "\n",
        "            # Tyrinėjimas\n",
        "            'was_exploration': was_exploration,\n",
        "            'best_q_card': best_q_card,\n",
        "            'best_q_value': round(best_q_value, 4),\n",
        "\n",
        "            # Thompson Sampling (jei taikoma)\n",
        "            'ts_sample_card1': round(ts_sample_card1, 4) if ts_sample_card1 is not None else None,\n",
        "            'ts_sample_card2': round(ts_sample_card2, 4) if ts_sample_card2 is not None else None,\n",
        "\n",
        "            # Panašumas\n",
        "            'sim_card1_to_rejected': round(similarity_card1_to_rejected, 4),\n",
        "            'sim_card2_to_rejected': round(similarity_card2_to_rejected, 4),\n",
        "\n",
        "            # Kaupiamieji\n",
        "            'cumulative_success': self.cumulative_success,\n",
        "            'cumulative_rejection': self.cumulative_rejection,\n",
        "\n",
        "            # Mokymosi progresas\n",
        "            'last_10_success_rate': round(last_10_rate, 4),\n",
        "            'last_20_success_rate': round(last_20_rate, 4),\n",
        "\n",
        "            # Serijos\n",
        "            'current_success_streak': self.current_success_streak,\n",
        "            'current_fail_streak': self.current_fail_streak,\n",
        "            'max_success_streak': self.max_success_streak,\n",
        "\n",
        "            # Sesija\n",
        "            'session_success': session_success,\n",
        "        }\n",
        "        self.records.append(record)\n",
        "\n",
        "    def get_dataframe(self) -> pd.DataFrame:\n",
        "        return pd.DataFrame(self.records)\n",
        "\n",
        "    def get_csv_string(self) -> str:\n",
        "        return self.get_dataframe().to_csv(index=False)\n",
        "\n",
        "    def save_csv(self, filename: str):\n",
        "        self.get_dataframe().to_csv(filename, index=False)\n",
        "        print(f\"Išsaugota: {filename}\")\n",
        "\n",
        "    def clear(self):\n",
        "        self.records = []\n",
        "        self.reset_cumulative()\n",
        "\n",
        "\n",
        "LOGGER = ExtendedResultsLogger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYOryIkAzE19"
      },
      "source": [
        "\n",
        "## Tyrinėjimo metodai\n",
        "---\n",
        "### 1. Epsilon-Greedy\n",
        "\n",
        "**Formulė:**\n",
        "$$a = \\begin{cases} \\text{random}(A) & \\text{su tikimybe } \\epsilon \\\\ \\arg\\max_a Q(s,a) & \\text{su tikimybe } 1-\\epsilon \\end{cases}$$\n",
        "\n",
        "**Pavyzdys su ε = 0.15:**\n",
        "```\n",
        "Q(Bananas) = 0.8, Q(Obuolys) = 0.3, Q(Kiviai) = 0.1\n",
        "\n",
        "random() = 0.23 (> 0.15) → Renkasi Bananą (max Q)\n",
        "random() = 0.08 (< 0.15) → Renkasi atsitiktinai (gal Kivius!)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Thompson Sampling\n",
        "\n",
        "**Formulė:**\n",
        "$$\\theta_i \\sim \\text{Beta}(\\alpha_i, \\beta_i)$$\n",
        "$$a = \\arg\\max_i \\theta_i$$\n",
        "\n",
        "**Kur:**\n",
        "- $\\alpha_i$ = atitikčių skaičius + 1\n",
        "- $\\beta_i$ = neatitikčių skaičius + 1\n",
        "- $\\theta_i$ = atsitiktinė reikšmė iš Beta pasiskirstymo\n",
        "\n",
        "\n",
        "**Pavyzdys:**\n",
        "```\n",
        "Bananas: 10 atitikčių, 2 neatitiktys → Beta(11, 3)\n",
        "Obuolys: 3 atiktys, 5 neatiktys  → Beta(4, 6)\n",
        "Kiviai:  1 atiktis, 8 neatiktys   → Beta(2, 9)\n",
        "\n",
        "Imame atsiktinę reikšmę:\n",
        "θ_Bananas = sample(Beta(11,3)) = 0.78\n",
        "θ_Obuolys = sample(Beta(4,6))  = 0.42\n",
        "θ_Kiviai  = sample(Beta(2,9))  = 0.15\n",
        "\n",
        "→ Renkasi Bananą (max θ = 0.78)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d15_9x_zE1-"
      },
      "source": [
        "## Strategijos\n",
        "\n",
        "### Strategija A: Panaši + Priešinga (Gylio/Pločio)\n",
        "\n",
        "```\n",
        "Rinkinys 1 (rejections=0):\n",
        "    → TOP 2 kortelės (pagal Q arba Thompson Sampling)\n",
        "\n",
        "Rinkinys 2+ (rejections≥1):\n",
        "    → 1 PANAŠIAUSIA į atmestąsias\n",
        "    → 1 PRIEŠINGIAUSIA\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Strategija B: 2 Panašiausios (Gylio)\n",
        "\n",
        "```\n",
        "Rinkinys 1 (rejections=0):\n",
        "    → TOP 2 kortelės\n",
        "\n",
        "Rinkinys 2+ (rejections≥1):\n",
        "    → 2 PANAŠIAUSIOS į atmestąsias\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Strategija C: Mišri (Gylio/Dažnio)\n",
        "\n",
        "```\n",
        "Rinkinys 1 (rejections=0):\n",
        "    → TOP 2 kortelės\n",
        "\n",
        "Rinkinys 2 (rejections=1):\n",
        "    → 1 PANAŠIAUSIA į atmestąsias\n",
        "    → 1 iš TOP (dar nerodyta)\n",
        "\n",
        "Rinkinys 3 (rejections=2):\n",
        "    → 2 PANAŠIAUSIOS\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE2ohx-rzE19"
      },
      "source": [
        "## Bazinis RL modelis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M68iC24TzE19"
      },
      "outputs": [],
      "source": [
        "class BaseRLModel:\n",
        "    def __init__(self, alpha: float, gamma: float, epsilon: float,\n",
        "                 exploration_method: str, strategy: str, similarity_method: str):\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.exploration_method = exploration_method\n",
        "        self.strategy = strategy\n",
        "        self.similarity_method = similarity_method\n",
        "        self.name = \"Base\"\n",
        "\n",
        "        self.q_table: Dict[State, Dict[str, float]] = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        self.successes: Dict[str, int] = defaultdict(int)\n",
        "        self.failures: Dict[str, int] = defaultdict(int)\n",
        "\n",
        "        self.current_state: State = State(0, 'start')\n",
        "        self.session_shown: List[str] = []\n",
        "        self.last_rejected: List[str] = []\n",
        "\n",
        "        self.similarity_matrix = SIMILARITY_MATRICES[similarity_method]\n",
        "\n",
        "        self.last_was_exploration = False\n",
        "        self.last_ts_samples: Dict[str, float] = {}\n",
        "\n",
        "    def get_q(self, state: State, food: str) -> float:\n",
        "        return self.q_table[state][food]\n",
        "\n",
        "    def get_best_q_info(self, state: State, available: List[str]) -> Tuple[str, float]:\n",
        "        q_vals = [(f, self.get_q(state, f)) for f in available]\n",
        "        q_vals.sort(key=lambda x: x[1], reverse=True)\n",
        "        return q_vals[0][0], q_vals[0][1]\n",
        "\n",
        "    def epsilon_greedy_select(self, state: State, available: List[str]) -> str:\n",
        "        if random.random() < self.epsilon:\n",
        "            self.last_was_exploration = True\n",
        "            return random.choice(available)\n",
        "        else:\n",
        "            self.last_was_exploration = False\n",
        "            best, _ = self.get_best_q_info(state, available)\n",
        "            return best\n",
        "\n",
        "    def thompson_sampling_select(self, available: List[str]) -> str:\n",
        "        self.last_ts_samples = {}\n",
        "        for food in available:\n",
        "            alpha = self.successes[food] + 1\n",
        "            beta = self.failures[food] + 1\n",
        "            self.last_ts_samples[food] = np.random.beta(alpha, beta)\n",
        "\n",
        "        sorted_foods = sorted(self.last_ts_samples.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.last_was_exploration = False\n",
        "        return sorted_foods[0][0]\n",
        "\n",
        "    def select_by_exploration(self, state: State, available: List[str]) -> str:\n",
        "        if self.exploration_method == 'thompson_sampling':\n",
        "            return self.thompson_sampling_select(available)\n",
        "        else:\n",
        "            return self.epsilon_greedy_select(state, available)\n",
        "\n",
        "    def get_top_cards(self, state: State, available: List[str], n: int = 2) -> List[str]:\n",
        "        if self.exploration_method == 'thompson_sampling':\n",
        "            self.last_ts_samples = {}\n",
        "            for food in available:\n",
        "                alpha = self.successes[food] + 1\n",
        "                beta = self.failures[food] + 1\n",
        "                self.last_ts_samples[food] = np.random.beta(alpha, beta)\n",
        "            sorted_foods = sorted(self.last_ts_samples.items(), key=lambda x: x[1], reverse=True)\n",
        "            self.last_was_exploration = False\n",
        "            return [f[0] for f in sorted_foods[:n]]\n",
        "        else:\n",
        "            result = []\n",
        "            remaining = available.copy()\n",
        "            for _ in range(n):\n",
        "                if not remaining:\n",
        "                    break\n",
        "                card = self.epsilon_greedy_select(state, remaining)\n",
        "                result.append(card)\n",
        "                remaining.remove(card)\n",
        "            return result\n",
        "\n",
        "    def get_similarity_to_rejected(self, card: str) -> float:\n",
        "        if not self.last_rejected:\n",
        "            return 0.0\n",
        "        card_idx = FOOD_LIST.index(card)\n",
        "        sims = [self.similarity_matrix[card_idx][FOOD_LIST.index(ref)]\n",
        "                for ref in self.last_rejected if ref in FOOD_LIST]\n",
        "        return np.mean(sims) if sims else 0.0\n",
        "\n",
        "    def get_most_similar(self, reference_cards: List[str], available: List[str], n: int = 1) -> List[str]:\n",
        "        if not reference_cards or not available:\n",
        "            return available[:n]\n",
        "        similarities = []\n",
        "        for food in available:\n",
        "            food_idx = FOOD_LIST.index(food)\n",
        "            avg_sim = np.mean([self.similarity_matrix[food_idx][FOOD_LIST.index(ref)]\n",
        "                              for ref in reference_cards if ref in FOOD_LIST])\n",
        "            similarities.append((food, avg_sim))\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [s[0] for s in similarities[:n]]\n",
        "\n",
        "    def get_most_opposite(self, reference_cards: List[str], available: List[str], n: int = 1) -> List[str]:\n",
        "        if not reference_cards or not available:\n",
        "            return available[:n]\n",
        "        similarities = []\n",
        "        for food in available:\n",
        "            food_idx = FOOD_LIST.index(food)\n",
        "            avg_sim = np.mean([self.similarity_matrix[food_idx][FOOD_LIST.index(ref)]\n",
        "                              for ref in reference_cards if ref in FOOD_LIST])\n",
        "            similarities.append((food, avg_sim))\n",
        "        similarities.sort(key=lambda x: x[1])\n",
        "        return [s[0] for s in similarities[:n]]\n",
        "\n",
        "    def select_cards(self) -> Tuple[str, str, str]:\n",
        "        available = [f for f in FOOD_LIST if f not in self.session_shown]\n",
        "        if len(available) < 2:\n",
        "            self.session_shown = []\n",
        "            available = FOOD_LIST.copy()\n",
        "\n",
        "        rejections = self.current_state.rejections\n",
        "\n",
        "        if self.strategy == 'A':\n",
        "            return self._strategy_A(available, rejections)\n",
        "        elif self.strategy == 'B':\n",
        "            return self._strategy_B(available, rejections)\n",
        "        else:\n",
        "            return self._strategy_C(available, rejections)\n",
        "\n",
        "    def _strategy_A(self, available: List[str], rejections: int) -> Tuple[str, str, str]:\n",
        "        if rejections == 0:\n",
        "            cards = self.get_top_cards(self.current_state, available, 2)\n",
        "            reason = f\"TOP2({self.exploration_method})\"\n",
        "        else:\n",
        "            similar = self.get_most_similar(self.last_rejected, available, 1)\n",
        "            remaining = [f for f in available if f not in similar]\n",
        "            opposite = self.get_most_opposite(self.last_rejected, remaining, 1) if remaining else similar\n",
        "            cards = similar + opposite\n",
        "            reason = f\"Panasus+Priesingas(rej={rejections})\"\n",
        "        self.session_shown.extend(cards[:2])\n",
        "        return (cards[0], cards[1] if len(cards) > 1 else cards[0], reason)\n",
        "\n",
        "    def _strategy_B(self, available: List[str], rejections: int) -> Tuple[str, str, str]:\n",
        "        if rejections == 0:\n",
        "            cards = self.get_top_cards(self.current_state, available, 2)\n",
        "            reason = f\"TOP2({self.exploration_method})\"\n",
        "        else:\n",
        "            cards = self.get_most_similar(self.last_rejected, available, 2)\n",
        "            reason = f\"2Panasus(rej={rejections})\"\n",
        "        self.session_shown.extend(cards[:2])\n",
        "        return (cards[0], cards[1] if len(cards) > 1 else cards[0], reason)\n",
        "\n",
        "    def _strategy_C(self, available: List[str], rejections: int) -> Tuple[str, str, str]:\n",
        "        if rejections == 0:\n",
        "            cards = self.get_top_cards(self.current_state, available, 2)\n",
        "            reason = f\"TOP2({self.exploration_method})\"\n",
        "        elif rejections == 1:\n",
        "            similar = self.get_most_similar(self.last_rejected, available, 1)\n",
        "            remaining = [f for f in available if f not in similar]\n",
        "            top_remaining = self.get_top_cards(self.current_state, remaining, 1) if remaining else similar\n",
        "            cards = similar + top_remaining\n",
        "            reason = \"Panasus+TOP\"\n",
        "        else:\n",
        "            cards = self.get_most_similar(self.last_rejected, available, 2)\n",
        "            reason = \"2Panasus\"\n",
        "        self.session_shown.extend(cards[:2])\n",
        "        return (cards[0], cards[1] if len(cards) > 1 else cards[0], reason)\n",
        "\n",
        "    def start_new_session(self):\n",
        "        self.session_shown = []\n",
        "        self.last_rejected = []\n",
        "        self.current_state = State(0, 'start')\n",
        "\n",
        "    def record_rejection(self, cards: List[str]):\n",
        "        self.last_rejected = cards.copy()\n",
        "        for card in cards:\n",
        "            self.failures[card] += 1\n",
        "\n",
        "    def record_success(self, chosen: str, other: str):\n",
        "        self.successes[chosen] += 1\n",
        "        self.failures[other] += 1\n",
        "\n",
        "    def update(self, state: State, action: Tuple[str, str], reward: float,\n",
        "               next_state: State, chosen: Optional[str] = None) -> Tuple[float, float]:\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxhOOwTgzE19"
      },
      "source": [
        "## Algoritmai\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Bendra TD (Temporal Difference) formulė:\n",
        "\n",
        "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\cdot [\\underbrace{r + \\gamma \\cdot V(s')}_{\\text{TD Target}} - Q(s,a)]$$\n",
        "\n",
        "**Kur:**\n",
        "- $Q(s,a)$ = dabartinis kortelės įvertinimas būsenoje s\n",
        "- $\\alpha$ = mokymosi greitis (learning rate)\n",
        "- $r$ = gautas apdovanojimas (+1 sėkmė, -1 atmetimas)\n",
        "- $\\gamma$ = ateities nuolaida (discount factor)\n",
        "- $V(s')$ = kitos būsenos vertė (skiriasi priklausomai nuo algoritmo)\n",
        "- $[...]$ = TD Error (skirtumas tarp tikėtino ir faktinio)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Q-Learning\n",
        "\n",
        "**Formulė:**\n",
        "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\cdot [r + \\gamma \\cdot \\max_{a'} Q(s',a') - Q(s,a)]$$\n",
        "\n",
        "**Kur:**\n",
        "- $\\max_{a'} Q(s',a')$ = **geriausio** galimo veiksmo vertė kitoje būsenoje\n",
        "\n",
        "---\n",
        "\n",
        "## 2. SARSA (State-Action-Reward-State-Action)\n",
        "\n",
        "**Formulė:**\n",
        "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\cdot [r + \\gamma \\cdot Q(s',a') - Q(s,a)]$$\n",
        "\n",
        "**Kur:**\n",
        "- $Q(s',a')$ = **faktinio** kito veiksmo vertė (to, kurį iš tikrųjų padarė)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Expected SARSA\n",
        "\n",
        "**Formulė:**\n",
        "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\cdot [r + \\gamma \\cdot \\mathbb{E}[Q(s',a')] - Q(s,a)]$$\n",
        "\n",
        "**Kur:**\n",
        "$$\\mathbb{E}[Q(s',a')] = (1-\\epsilon) \\cdot \\max_{a'} Q(s',a') + \\epsilon \\cdot \\frac{1}{|A|} \\sum_{a'} Q(s',a')$$\n",
        "\n",
        "**Arba paprasčiau:**\n",
        "- $\\mathbb{E}[Q(s',a')]$ = **tikėtina** kito veiksmo vertė (vidurkis pagal tikimybes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZuGmlcdzE1-"
      },
      "outputs": [],
      "source": [
        "class QLearningModel(BaseRLModel):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.name = \"Q-Learning\"\n",
        "\n",
        "    def update(self, state: State, action: Tuple[str, str], reward: float,\n",
        "               next_state: State, chosen: Optional[str] = None) -> Tuple[float, float]:\n",
        "        card1, card2 = action\n",
        "\n",
        "        max_next_q = max(self.get_q(next_state, f) for f in FOOD_LIST)\n",
        "\n",
        "        reward_other = -0.2\n",
        "\n",
        "        if chosen is None:\n",
        "            for card in [card1, card2]:\n",
        "                old_q = self.get_q(state, card)\n",
        "                # TD Target = r + γ·max Q(s',a')\n",
        "                td_target = reward + self.gamma * max_next_q\n",
        "                # Q ← Q + α·(TD_target - Q)\n",
        "                self.q_table[state][card] = old_q + self.alpha * (td_target - old_q)\n",
        "            return (self.get_q(state, card1), self.get_q(state, card2))\n",
        "        else:\n",
        "            other = card2 if chosen == card1 else card1\n",
        "\n",
        "            old_q = self.get_q(state, chosen)\n",
        "            td_target = reward + self.gamma * max_next_q\n",
        "            self.q_table[state][chosen] = old_q + self.alpha * (td_target - old_q)\n",
        "\n",
        "            old_q_other = self.get_q(state, other)\n",
        "            td_target_other = reward_other + self.gamma * max_next_q\n",
        "            self.q_table[state][other] = old_q_other + self.alpha * (td_target_other - old_q_other)\n",
        "\n",
        "            return (self.get_q(state, card1), self.get_q(state, card2))\n",
        "\n",
        "\n",
        "class SARSAModel(BaseRLModel):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.name = \"SARSA\"\n",
        "\n",
        "    def update(self, state: State, action: Tuple[str, str], reward: float,\n",
        "               next_state: State, chosen: Optional[str] = None) -> Tuple[float, float]:\n",
        "        card1, card2 = action\n",
        "\n",
        "        available = [f for f in FOOD_LIST if f not in self.session_shown]\n",
        "        if len(available) >= 2:\n",
        "            next_card1 = self.select_by_exploration(next_state, available)\n",
        "            next_card2 = self.select_by_exploration(next_state, [f for f in available if f != next_card1])\n",
        "            next_q = (self.get_q(next_state, next_card1) + self.get_q(next_state, next_card2)) / 2\n",
        "        else:\n",
        "            next_q = 0\n",
        "\n",
        "        reward_other = -0.2\n",
        "\n",
        "        if chosen is None:\n",
        "            for card in [card1, card2]:\n",
        "                old_q = self.get_q(state, card)\n",
        "                td_target = reward + self.gamma * next_q\n",
        "                self.q_table[state][card] = old_q + self.alpha * (td_target - old_q)\n",
        "            return (self.get_q(state, card1), self.get_q(state, card2))\n",
        "        else:\n",
        "            other = card2 if chosen == card1 else card1\n",
        "\n",
        "            old_q = self.get_q(state, chosen)\n",
        "            td_target = reward + self.gamma * next_q\n",
        "            self.q_table[state][chosen] = old_q + self.alpha * (td_target - old_q)\n",
        "\n",
        "            old_q_other = self.get_q(state, other)\n",
        "            td_target_other = reward_other + self.gamma * next_q\n",
        "            self.q_table[state][other] = old_q_other + self.alpha * (td_target_other - old_q_other)\n",
        "\n",
        "            return (self.get_q(state, card1), self.get_q(state, card2))\n",
        "\n",
        "\n",
        "class ExpectedSARSAModel(BaseRLModel):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.name = \"Expected-SARSA\"\n",
        "\n",
        "    def get_expected_q(self, state: State, available: List[str]) -> float:\n",
        "        if not available:\n",
        "            return 0.0\n",
        "        q_vals = [self.get_q(state, f) for f in available]\n",
        "        max_q = max(q_vals)\n",
        "        mean_q = sum(q_vals) / len(q_vals)\n",
        "        # Tikėtina Q = (1-ε)·geriausias + ε·vidurkis\n",
        "        return (1 - self.epsilon) * max_q + self.epsilon * mean_q\n",
        "\n",
        "    def update(self, state: State, action: Tuple[str, str], reward: float,\n",
        "               next_state: State, chosen: Optional[str] = None) -> Tuple[float, float]:\n",
        "        card1, card2 = action\n",
        "\n",
        "        available = [f for f in FOOD_LIST if f not in self.session_shown]\n",
        "        if len(available) < 2:\n",
        "            available = FOOD_LIST.copy()\n",
        "\n",
        "        # E[Q(s',a')]\n",
        "        expected_q = self.get_expected_q(next_state, available)\n",
        "        reward_other = -0.2\n",
        "\n",
        "        if chosen is None:\n",
        "            for card in [card1, card2]:\n",
        "                old_q = self.get_q(state, card)\n",
        "                td_target = reward + self.gamma * expected_q\n",
        "                self.q_table[state][card] = old_q + self.alpha * (td_target - old_q)\n",
        "            return (self.get_q(state, card1), self.get_q(state, card2))\n",
        "        else:\n",
        "            other = card2 if chosen == card1 else card1\n",
        "\n",
        "            old_q = self.get_q(state, chosen)\n",
        "            td_target = reward + self.gamma * expected_q\n",
        "            self.q_table[state][chosen] = old_q + self.alpha * (td_target - old_q)\n",
        "\n",
        "            old_q_other = self.get_q(state, other)\n",
        "            td_target_other = reward_other + self.gamma * expected_q\n",
        "            self.q_table[state][other] = old_q_other + self.alpha * (td_target_other - old_q_other)\n",
        "\n",
        "            return (self.get_q(state, card1), self.get_q(state, card2))\n",
        "\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'Q-Learning': QLearningModel,\n",
        "    'SARSA': SARSAModel,\n",
        "    'Expected-SARSA': ExpectedSARSAModel\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57b2YyxLzE1-"
      },
      "source": [
        "##Virtualaus vaiko simuliacija\n",
        "\n",
        "```\n",
        "Jei norimas vaisius yra tarp rodomų kortelių:\n",
        "    → PASIRENKA\n",
        "Kitaip:\n",
        "    → ATMETA\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlgI_5sjzE1-"
      },
      "outputs": [],
      "source": [
        "class VirtualChild:\n",
        "    def __init__(self, wants_list: List[str]):\n",
        "        self.wants_list = wants_list\n",
        "        self.current_want_index = 0\n",
        "\n",
        "    def get_current_want(self) -> Optional[str]:\n",
        "        if self.current_want_index < len(self.wants_list):\n",
        "            return self.wants_list[self.current_want_index]\n",
        "        return None\n",
        "\n",
        "    def next_want(self):\n",
        "        self.current_want_index += 1\n",
        "\n",
        "    def react_to_cards(self, card1: str, card2: str) -> Optional[str]:\n",
        "        want = self.get_current_want()\n",
        "        if want == card1:\n",
        "            return card1\n",
        "        elif want == card2:\n",
        "            return card2\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_want_index = 0\n",
        "\n",
        "\n",
        "def run_simulation(model: BaseRLModel, child: VirtualChild, logger: ExtendedResultsLogger) -> Dict:\n",
        "\n",
        "    child.reset()\n",
        "    model.start_new_session()\n",
        "    logger.reset_cumulative()\n",
        "\n",
        "    session_num = 0\n",
        "    sessions_succeeded = 0\n",
        "    sessions_failed = 0\n",
        "\n",
        "    reward_success = 1.0\n",
        "    reward_rejection = -1.0\n",
        "\n",
        "    while child.get_current_want() is not None:\n",
        "        session_num += 1\n",
        "        wanted = child.get_current_want()\n",
        "        model.start_new_session()\n",
        "\n",
        "        session_success = False\n",
        "\n",
        "        for set_number in range(1, 4):\n",
        "            state = model.current_state\n",
        "            card1, card2, reason = model.select_cards()\n",
        "\n",
        "            q1_before = model.get_q(state, card1)\n",
        "            q2_before = model.get_q(state, card2)\n",
        "\n",
        "            best_q_card, best_q_value = model.get_best_q_info(state, FOOD_LIST)\n",
        "\n",
        "            sim1 = model.get_similarity_to_rejected(card1)\n",
        "            sim2 = model.get_similarity_to_rejected(card2)\n",
        "\n",
        "            ts1 = model.last_ts_samples.get(card1) if model.exploration_method == 'thompson_sampling' else None\n",
        "            ts2 = model.last_ts_samples.get(card2) if model.exploration_method == 'thompson_sampling' else None\n",
        "\n",
        "            chosen = child.react_to_cards(card1, card2)\n",
        "\n",
        "            if chosen is not None:\n",
        "                other = card2 if chosen == card1 else card1\n",
        "                next_state = State(0, 'success')\n",
        "\n",
        "                q1_after, q2_after = model.update(state, (card1, card2), reward_success, next_state, chosen)\n",
        "                model.record_success(chosen, other)\n",
        "                model.current_state = next_state\n",
        "\n",
        "                logger.log(\n",
        "                    session=session_num, wanted=wanted, card1=card1, card2=card2,\n",
        "                    result='SUCCESS', chosen=chosen, set_number=set_number, state=state,\n",
        "                    selection_reason=reason, model_name=model.name,\n",
        "                    exploration=model.exploration_method, strategy=model.strategy,\n",
        "                    alpha=model.alpha, gamma=model.gamma, epsilon=model.epsilon,\n",
        "                    similarity_method=model.similarity_method,\n",
        "                    q1_before=q1_before, q2_before=q2_before, q1_after=q1_after, q2_after=q2_after,\n",
        "                    was_exploration=model.last_was_exploration,\n",
        "                    best_q_card=best_q_card, best_q_value=best_q_value,\n",
        "                    ts_sample_card1=ts1, ts_sample_card2=ts2,\n",
        "                    similarity_card1_to_rejected=sim1, similarity_card2_to_rejected=sim2,\n",
        "                    session_success=True\n",
        "                )\n",
        "\n",
        "                session_success = True\n",
        "                sessions_succeeded += 1\n",
        "                break\n",
        "            else:\n",
        "                next_state = State(min(state.rejections + 1, 3), 'rejection')\n",
        "\n",
        "                q1_after, q2_after = model.update(state, (card1, card2), reward_rejection, next_state, None)\n",
        "                model.record_rejection([card1, card2])\n",
        "                model.current_state = next_state\n",
        "\n",
        "                logger.log(\n",
        "                    session=session_num, wanted=wanted, card1=card1, card2=card2,\n",
        "                    result='REJECTION', chosen='', set_number=set_number, state=state,\n",
        "                    selection_reason=reason, model_name=model.name,\n",
        "                    exploration=model.exploration_method, strategy=model.strategy,\n",
        "                    alpha=model.alpha, gamma=model.gamma, epsilon=model.epsilon,\n",
        "                    similarity_method=model.similarity_method,\n",
        "                    q1_before=q1_before, q2_before=q2_before, q1_after=q1_after, q2_after=q2_after,\n",
        "                    was_exploration=model.last_was_exploration,\n",
        "                    best_q_card=best_q_card, best_q_value=best_q_value,\n",
        "                    ts_sample_card1=ts1, ts_sample_card2=ts2,\n",
        "                    similarity_card1_to_rejected=sim1, similarity_card2_to_rejected=sim2,\n",
        "                    session_success=False\n",
        "                )\n",
        "\n",
        "        if not session_success:\n",
        "            sessions_failed += 1\n",
        "\n",
        "        child.next_want()\n",
        "\n",
        "    return {\n",
        "        'model': model.name,\n",
        "        'exploration': model.exploration_method,\n",
        "        'strategy': model.strategy,\n",
        "        'alpha': model.alpha,\n",
        "        'gamma': model.gamma,\n",
        "        'epsilon': model.epsilon,\n",
        "        'similarity': model.similarity_method,\n",
        "        'total_sessions': session_num,\n",
        "        'sessions_succeeded': sessions_succeeded,\n",
        "        'sessions_failed': sessions_failed,\n",
        "        'success_rate': sessions_succeeded / session_num * 100 if session_num > 0 else 0,\n",
        "        'max_success_streak': logger.max_success_streak\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY7DKtQczE1_"
      },
      "source": [
        "## Simuliacijos paleidimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtRom8oSzE1_"
      },
      "outputs": [],
      "source": [
        "LOGGER.clear()\n",
        "results_summary = []\n",
        "\n",
        "all_combinations = list(itertools.product(\n",
        "    MODEL_CLASSES.keys(),\n",
        "    PARAM_GRID['exploration_method'],\n",
        "    PARAM_GRID['strategy'],\n",
        "    PARAM_GRID['alpha'],\n",
        "    PARAM_GRID['gamma'],\n",
        "    PARAM_GRID['epsilon'],\n",
        "    PARAM_GRID['similarity_method']\n",
        "))\n",
        "\n",
        "print(f\"PALEIDŽIAMOS {len(all_combinations)} SIMULIACIJOS...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for i, (model_name, expl, strat, alpha, gamma, eps, sim) in enumerate(all_combinations):\n",
        "    ModelClass = MODEL_CLASSES[model_name]\n",
        "    model = ModelClass(\n",
        "        alpha=alpha,\n",
        "        gamma=gamma,\n",
        "        epsilon=eps,\n",
        "        exploration_method=expl,\n",
        "        strategy=strat,\n",
        "        similarity_method=sim\n",
        "    )\n",
        "\n",
        "    child = VirtualChild(CHILD_WANTS)\n",
        "\n",
        "    result = run_simulation(model, child, LOGGER)\n",
        "    results_summary.append(result)\n",
        "\n",
        "    if (i + 1) % 50 == 0 or (i + 1) == len(all_combinations):\n",
        "        print(f\"   [{i+1}/{len(all_combinations)}] Baigta...\")\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nIš viso {len(results_summary)} simuliacijų\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF43lDzqzE1_"
      },
      "source": [
        "## TOP konfigūracijų suvestinė"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFGFBiDzzE2A"
      },
      "outputs": [],
      "source": [
        "summary_df = pd.DataFrame(results_summary)\n",
        "summary_df = summary_df.sort_values('success_rate', ascending=False)\n",
        "\n",
        "print(f\"REZULTATŲ SUVESTINĖ ({len(summary_df)} kombinacijų)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nTOP 20 KONFIGŪRACIJŲ:\")\n",
        "display(summary_df.head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-bYvkRzE2A"
      },
      "source": [
        "## Eksportuoti rezultatus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV-MBhQKzE2A"
      },
      "outputs": [],
      "source": [
        "summary_df.to_csv('suvestine.csv', index=False)\n",
        "print(\"Išsaugota: suvestine.csv\")\n",
        "\n",
        "LOGGER.save_csv('detalus_rezultatai.csv')\n",
        "\n",
        "print(f\"\\nSuvestinė: {len(summary_df)} eilučių\")\n",
        "print(f\"Detalūs rezultatai: {len(LOGGER.records)} eilučių\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PphQL7AgzE2A"
      },
      "source": [
        "## Trumpa rezultatų analizė"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKD1lRd0zE2A"
      },
      "outputs": [],
      "source": [
        "for param in ['model', 'exploration', 'strategy', 'alpha', 'gamma', 'epsilon', 'similarity']:\n",
        "    print(f\"\\n{param.upper()}:\")\n",
        "    stats = summary_df.groupby(param)['success_rate'].agg(['mean', 'std']).round(2)\n",
        "    stats = stats.sort_values('mean', ascending=False)\n",
        "    for idx, row in stats.iterrows():\n",
        "        print(f\"  {idx}: {row['mean']:.1f}% (±{row['std']:.1f}%)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_JtNtGD2zE18",
        "ifoRlMH3zE18",
        "QE2ohx-rzE19",
        "nxhOOwTgzE19",
        "57b2YyxLzE1-",
        "bY7DKtQczE1_",
        "nF43lDzqzE1_",
        "EY-bYvkRzE2A",
        "PphQL7AgzE2A"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}